{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0913f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DELIVERABLE 1: EXPERIMENT TRACKING\n",
      "================================================================================\n",
      "\n",
      "Objective: Determine if census data and other improvements add signal\n",
      "\n",
      "================================================================================\n",
      "PART 1: TESTING CENSUS DATA\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/11 19:05:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: Train MAPE=3.50%, Test MAPE=5.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/11 19:06:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with_raw_census: Train MAPE=3.57%, Test MAPE=5.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/11 19:06:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with_engineered_census: Train MAPE=3.58%, Test MAPE=6.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/11 19:06:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "census_only: Train MAPE=13.14%, Test MAPE=14.27%\n",
      "\n",
      "Census Data Conclusion: NO improvement - baseline is best\n",
      "\n",
      "================================================================================\n",
      "PART 2: TESTING OTHER IMPROVEMENTS\n",
      "================================================================================\n",
      "\n",
      "[1/2] Testing: Remove outliers from training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/11 19:07:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Removed 849 outliers\n",
      "  Test MAPE: 5.44%\n",
      "\n",
      "[2/2] Testing: Log-only transformation (no z-score)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/11 19:07:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Test MAPE: 5.77%\n",
      "\n",
      "================================================================================\n",
      "FINAL RESULTS SUMMARY\n",
      "================================================================================\n",
      "Approach                               Test MAPE     vs Baseline\n",
      "--------------------------------------------------------------------------------\n",
      "Original Baseline (z-norm log)             5.86%               —\n",
      "Census Data (best attempt)                 5.98%         -0.12pp\n",
      "Remove Outliers                            5.44%         +0.42pp\n",
      "Log-only Transform                         5.77%         +0.09pp\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CONCLUSION\n",
      "================================================================================\n",
      "Best Model: Remove Outliers + Baseline Features\n",
      "Test MAPE: 5.44%\n",
      "Improvement: 0.42 percentage points (7.2% relative improvement)\n",
      "\n",
      "Key Findings:\n",
      "1. Census data DOES NOT improve predictions\n",
      "2. Removing outliers (3 sigma filter) IMPROVES performance by 0.42pp\n",
      "3. Simplified log transformation slightly improves over z-normalized approach\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "\n",
    "# Load data\n",
    "census_df = pd.read_csv('census.csv', index_col=0)\n",
    "train_df_original = pd.read_csv('train.csv', index_col=0)\n",
    "test_df_original = pd.read_csv('test.csv', index_col=0)\n",
    "df_2022 = pd.read_csv('data_2022.csv', index_col=0)\n",
    "\n",
    "# Calculate train statistics\n",
    "train_mean = train_df_original['price'].apply(np.log).mean()\n",
    "train_std = train_df_original['price'].apply(np.log).std()\n",
    "\n",
    "def median_absolute_percentage_error(actual, predicted):\n",
    "    return np.median((np.abs(actual - predicted) / actual)) * 100\n",
    "\n",
    "def inv_zscore_log_price(y, mean, std):\n",
    "    return np.exp((y * std) + mean)\n",
    "\n",
    "mlflow.set_experiment(\"beekin_rent_prediction\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DELIVERABLE 1: EXPERIMENT TRACKING\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nObjective: Determine if census data and other improvements add signal\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: CENSUS DATA EXPERIMENTS\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"PART 1: TESTING CENSUS DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Merge census data\n",
    "train_with_census = train_df_original.merge(census_df, on='blockgroup', how='left')\n",
    "test_with_census = test_df_original.merge(census_df, on='blockgroup', how='left')\n",
    "\n",
    "# Create engineered features\n",
    "for df in [train_with_census, test_with_census]:\n",
    "    df['population'] = df['population'].fillna(1)\n",
    "    df['education_rate'] = df['education'] / df['population']\n",
    "    df['housing_density'] = df['housing'] / df['population']\n",
    "    df['commuter_rate'] = df['transportation'] / df['population']\n",
    "    df['population_log'] = np.log1p(df['population'])\n",
    "    df['education_rate'] = df['education_rate'].fillna(0)\n",
    "    df['housing_density'] = df['housing_density'].fillna(0)\n",
    "    df['commuter_rate'] = df['commuter_rate'].fillna(0)\n",
    "    df['population_log'] = df['population_log'].fillna(0)\n",
    "\n",
    "experiments_census = {\n",
    "    'baseline': {\n",
    "        'features': ['latitude', 'longitude', 'property_type', 'sqft', 'beds', 'baths', 'days_since_2014'],\n",
    "        'use_census': False\n",
    "    },\n",
    "    'with_raw_census': {\n",
    "        'features': ['latitude', 'longitude', 'property_type', 'sqft', 'beds', 'baths', 'days_since_2014', \n",
    "                    'population', 'housing', 'education', 'transportation'],\n",
    "        'use_census': True\n",
    "    },\n",
    "    'with_engineered_census': {\n",
    "        'features': ['latitude', 'longitude', 'property_type', 'sqft', 'beds', 'baths', 'days_since_2014',\n",
    "                    'education_rate', 'housing_density', 'commuter_rate', 'population_log'],\n",
    "        'use_census': True\n",
    "    },\n",
    "    'census_only': {\n",
    "        'features': ['education_rate', 'housing_density', 'commuter_rate', 'population_log'],\n",
    "        'use_census': True\n",
    "    }\n",
    "}\n",
    "\n",
    "results_census = {}\n",
    "\n",
    "for exp_name, exp_config in experiments_census.items():\n",
    "    with mlflow.start_run(run_name=exp_name):\n",
    "        if exp_config['use_census']:\n",
    "            train_data = train_with_census\n",
    "            test_data = test_with_census\n",
    "        else:\n",
    "            train_data = train_df_original\n",
    "            test_data = test_df_original\n",
    "        \n",
    "        features = exp_config['features']\n",
    "        X_train = train_data[features].fillna(0)\n",
    "        y_train = train_data['trans_log_price']\n",
    "        X_test = test_data[features].fillna(0)\n",
    "        y_test = test_data['trans_log_price']\n",
    "        \n",
    "        mlflow.log_param(\"features\", features)\n",
    "        mlflow.log_param(\"n_features\", len(features))\n",
    "        mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "        mlflow.log_param(\"n_train_samples\", len(X_train))\n",
    "        \n",
    "        model = xgb.XGBRegressor(\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=111,\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.3,\n",
    "            max_depth=6\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        train_pred = inv_zscore_log_price(model.predict(X_train), train_mean, train_std)\n",
    "        test_pred = inv_zscore_log_price(model.predict(X_test), train_mean, train_std)\n",
    "        train_actual = inv_zscore_log_price(y_train, train_mean, train_std)\n",
    "        test_actual = inv_zscore_log_price(y_test, train_mean, train_std)\n",
    "        \n",
    "        train_mape = median_absolute_percentage_error(train_actual, train_pred)\n",
    "        test_mape = median_absolute_percentage_error(test_actual, test_pred)\n",
    "        \n",
    "        mlflow.log_metric(\"train_mape\", train_mape)\n",
    "        mlflow.log_metric(\"test_mape\", test_mape)\n",
    "        mlflow.log_metric(\"overfitting_gap\", test_mape - train_mape)\n",
    "        mlflow.xgboost.log_model(model, \"model\")\n",
    "        \n",
    "        results_census[exp_name] = {'train_mape': train_mape, 'test_mape': test_mape}\n",
    "        print(f\"{exp_name}: Train MAPE={train_mape:.2f}%, Test MAPE={test_mape:.2f}%\")\n",
    "\n",
    "print(\"\\nCensus Data Conclusion: NO improvement - baseline is best\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: MODEL IMPROVEMENT EXPERIMENTS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART 2: TESTING OTHER IMPROVEMENTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_improvements = {}\n",
    "\n",
    "# Improvement 1: Remove outliers\n",
    "print(\"\\n[1/2] Testing: Remove outliers from training...\")\n",
    "with mlflow.start_run(run_name=\"remove_outliers\"):\n",
    "    price_mean = train_df_original['price'].mean()\n",
    "    price_std = train_df_original['price'].std()\n",
    "    \n",
    "    train_clean = train_df_original[\n",
    "        (train_df_original['price'] > price_mean - 3*price_std) & \n",
    "        (train_df_original['price'] < price_mean + 3*price_std)\n",
    "    ].copy()\n",
    "    \n",
    "    train_mean_clean = train_clean['price'].apply(np.log).mean()\n",
    "    train_std_clean = train_clean['price'].apply(np.log).std()\n",
    "    \n",
    "    features = ['latitude', 'longitude', 'property_type', 'sqft', 'beds', 'baths', 'days_since_2014']\n",
    "    X_train = train_clean[features]\n",
    "    y_train = train_clean['trans_log_price']\n",
    "    X_test = test_df_original[features]\n",
    "    y_test = test_df_original['trans_log_price']\n",
    "    \n",
    "    model = xgb.XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=111,\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.3\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    test_pred = inv_zscore_log_price(model.predict(X_test), train_mean_clean, train_std_clean)\n",
    "    test_actual = inv_zscore_log_price(y_test, train_mean_clean, train_std_clean)\n",
    "    test_mape = median_absolute_percentage_error(test_actual, test_pred)\n",
    "    \n",
    "    mlflow.log_param(\"outliers_removed\", True)\n",
    "    mlflow.log_param(\"n_samples_removed\", len(train_df_original) - len(train_clean))\n",
    "    mlflow.log_metric(\"test_mape\", test_mape)\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n",
    "    \n",
    "    results_improvements['remove_outliers'] = test_mape\n",
    "    print(f\"  Removed {len(train_df_original) - len(train_clean)} outliers\")\n",
    "    print(f\"  Test MAPE: {test_mape:.2f}%\")\n",
    "\n",
    "# Improvement 2: Log-only transformation\n",
    "print(\"\\n[2/2] Testing: Log-only transformation (no z-score)...\")\n",
    "with mlflow.start_run(run_name=\"log_only_transform\"):\n",
    "    features = ['latitude', 'longitude', 'property_type', 'sqft', 'beds', 'baths', 'days_since_2014']\n",
    "    X_train = train_df_original[features]\n",
    "    y_train_log = np.log(train_df_original['price'])\n",
    "    X_test = test_df_original[features]\n",
    "    \n",
    "    model = xgb.XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=111,\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.3\n",
    "    )\n",
    "    model.fit(X_train, y_train_log)\n",
    "    \n",
    "    test_pred = np.exp(model.predict(X_test))\n",
    "    test_actual = test_df_original['price'].values\n",
    "    test_mape = median_absolute_percentage_error(test_actual, test_pred)\n",
    "    \n",
    "    mlflow.log_param(\"transform\", \"log_only\")\n",
    "    mlflow.log_metric(\"test_mape\", test_mape)\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n",
    "    \n",
    "    results_improvements['log_only'] = test_mape\n",
    "    print(f\"  Test MAPE: {test_mape:.2f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Approach':<35} {'Test MAPE':>12} {'vs Baseline':>15}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'Original Baseline (z-norm log)':<35} {5.86:>11.2f}% {'—':>15}\")\n",
    "print(f\"{'Census Data (best attempt)':<35} {5.98:>11.2f}% {'-0.12pp':>15}\")\n",
    "print(f\"{'Remove Outliers':<35} {results_improvements['remove_outliers']:>11.2f}% {'+0.42pp':>15}\")\n",
    "print(f\"{'Log-only Transform':<35} {results_improvements['log_only']:>11.2f}% {'+0.09pp':>15}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSION\")\n",
    "print(\"=\"*80)\n",
    "print(\"Best Model: Remove Outliers + Baseline Features\")\n",
    "print(f\"Test MAPE: {results_improvements['remove_outliers']:.2f}%\")\n",
    "print(f\"Improvement: {5.86 - results_improvements['remove_outliers']:.2f} percentage points (7.2% relative improvement)\")\n",
    "print(\"\\nKey Findings:\")\n",
    "print(\"1. Census data DOES NOT improve predictions\")\n",
    "print(\"2. Removing outliers (3 sigma filter) IMPROVES performance by 0.42pp\")\n",
    "print(\"3. Simplified log transformation slightly improves over z-normalized approach\")\n",
    "print(\"=\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9548d188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running experiment: baseline\n",
      "============================================================\n",
      "X_train shape: (46499, 7)\n",
      "y_train shape: (46499,)\n",
      "X_test shape: (10325, 7)\n",
      "y_test shape: (10325,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/11 13:53:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train MAPE: 3.50%\n",
      "  Test MAPE: 5.86%\n",
      "  Overfitting Gap: 2.35%\n",
      "  Train MAE: $47.12\n",
      "  Test MAE: $79.45\n",
      "\n",
      "============================================================\n",
      "Running experiment: with_raw_census\n",
      "============================================================\n",
      "X_train shape: (185996, 11)\n",
      "y_train shape: (185996,)\n",
      "X_test shape: (41300, 11)\n",
      "y_test shape: (41300,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/11 13:53:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train MAPE: 3.57%\n",
      "  Test MAPE: 5.98%\n",
      "  Overfitting Gap: 2.42%\n",
      "  Train MAE: $47.91\n",
      "  Test MAE: $80.10\n",
      "\n",
      "============================================================\n",
      "Running experiment: with_engineered_census\n",
      "============================================================\n",
      "X_train shape: (185996, 11)\n",
      "y_train shape: (185996,)\n",
      "X_test shape: (41300, 11)\n",
      "y_test shape: (41300,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/11 13:53:44 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train MAPE: 3.58%\n",
      "  Test MAPE: 6.04%\n",
      "  Overfitting Gap: 2.46%\n",
      "  Train MAE: $47.45\n",
      "  Test MAE: $81.50\n",
      "\n",
      "============================================================\n",
      "Running experiment: census_only\n",
      "============================================================\n",
      "X_train shape: (185996, 4)\n",
      "y_train shape: (185996,)\n",
      "X_test shape: (41300, 4)\n",
      "y_test shape: (41300,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/11 13:53:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train MAPE: 13.14%\n",
      "  Test MAPE: 14.27%\n",
      "  Overfitting Gap: 1.13%\n",
      "  Train MAE: $170.68\n",
      "  Test MAE: $190.05\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT COMPARISON\n",
      "================================================================================\n",
      "Experiment                       Train MAPE    Test MAPE  Improvement\n",
      "--------------------------------------------------------------------------------\n",
      "baseline                              3.50%        5.86%        0.0%\n",
      "with_raw_census                       3.57%        5.98%       -2.1%\n",
      "with_engineered_census                3.58%        6.04%       -3.1%\n",
      "census_only                          13.14%       14.27%     -143.5%\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CONCLUSION: Census Data Impact\n",
      "================================================================================\n",
      "\n",
      "Best performing model: baseline\n",
      "Test MAPE: 5.86%\n",
      "\n",
      "Census data DID NOT improve model performance\n",
      "\n",
      "Recommendation: EXCLUDE census features - adds complexity without benefit\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# import mlflow\n",
    "# import mlflow.xgboost\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import xgboost as xgb\n",
    "\n",
    "# # Load data\n",
    "# census_df = pd.read_csv('census.csv', index_col=0)\n",
    "# train_df = pd.read_csv('train.csv', index_col=0)\n",
    "# test_df = pd.read_csv('test.csv', index_col=0)\n",
    "# df_2022 = pd.read_csv('data_2022.csv', index_col=0)\n",
    "\n",
    "# # Calculate train statistics (from ORIGINAL train_df)\n",
    "# train_mean = train_df['price'].apply(np.log).mean()\n",
    "# train_std = train_df['price'].apply(np.log).std()\n",
    "\n",
    "# def median_absolute_percentage_error(actual, predicted):\n",
    "#     return np.median((np.abs(actual - predicted) / actual)) * 100\n",
    "\n",
    "# def inv_zscore_log_price(y, mean, std):\n",
    "#     return np.exp((y * std) + mean)\n",
    "\n",
    "# # Merge census data with train and test\n",
    "# train_with_census = train_df.merge(census_df, on='blockgroup', how='left')\n",
    "# test_with_census = test_df.merge(census_df, on='blockgroup', how='left')\n",
    "\n",
    "# # Create engineered features\n",
    "# for df in [train_with_census, test_with_census]:\n",
    "#     # Handle division by zero\n",
    "#     df['population'] = df['population'].fillna(1)  # Avoid division by zero\n",
    "#     df['education_rate'] = df['education'] / df['population']\n",
    "#     df['housing_density'] = df['housing'] / df['population']\n",
    "#     df['commuter_rate'] = df['transportation'] / df['population']\n",
    "#     df['population_log'] = np.log1p(df['population'])\n",
    "    \n",
    "#     # Fill any remaining NaNs\n",
    "#     df['education_rate'] = df['education_rate'].fillna(0)\n",
    "#     df['housing_density'] = df['housing_density'].fillna(0)\n",
    "#     df['commuter_rate'] = df['commuter_rate'].fillna(0)\n",
    "#     df['population_log'] = df['population_log'].fillna(0)\n",
    "\n",
    "# # Set up MLflow\n",
    "# mlflow.set_experiment(\"beekin_rent_prediction\")\n",
    "\n",
    "# # Define experiments\n",
    "# experiments = {\n",
    "#     'baseline': {\n",
    "#         'features': ['latitude', 'longitude', 'property_type', 'sqft', 'beds', 'baths', 'days_since_2014'],\n",
    "#         'use_census': False\n",
    "#     },\n",
    "#     'with_raw_census': {\n",
    "#         'features': ['latitude', 'longitude', 'property_type', 'sqft', 'beds', 'baths', 'days_since_2014', \n",
    "#                     'population', 'housing', 'education', 'transportation'],\n",
    "#         'use_census': True\n",
    "#     },\n",
    "#     'with_engineered_census': {\n",
    "#         'features': ['latitude', 'longitude', 'property_type', 'sqft', 'beds', 'baths', 'days_since_2014',\n",
    "#                     'education_rate', 'housing_density', 'commuter_rate', 'population_log'],\n",
    "#         'use_census': True\n",
    "#     },\n",
    "#     'census_only': {\n",
    "#         'features': ['education_rate', 'housing_density', 'commuter_rate', 'population_log'],\n",
    "#         'use_census': True\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Run experiments\n",
    "# results = {}\n",
    "\n",
    "# for exp_name, exp_config in experiments.items():\n",
    "#     print(f\"\\n{'='*60}\")\n",
    "#     print(f\"Running experiment: {exp_name}\")\n",
    "#     print(f\"{'='*60}\")\n",
    "    \n",
    "#     with mlflow.start_run(run_name=exp_name):\n",
    "#         # Select the right dataframe\n",
    "#         if exp_config['use_census']:\n",
    "#             train_data = train_with_census\n",
    "#             test_data = test_with_census\n",
    "#         else:\n",
    "#             train_data = train_df\n",
    "#             test_data = test_df\n",
    "        \n",
    "#         # Prepare features and labels from THE SAME dataframe\n",
    "#         features = exp_config['features']\n",
    "#         X_train = train_data[features].copy()\n",
    "#         y_train = train_data['trans_log_price'].copy()\n",
    "        \n",
    "#         X_test = test_data[features].copy()\n",
    "#         y_test = test_data['trans_log_price'].copy()\n",
    "        \n",
    "#         # Fill any NaNs\n",
    "#         X_train = X_train.fillna(0)\n",
    "#         X_test = X_test.fillna(0)\n",
    "        \n",
    "#         print(f\"X_train shape: {X_train.shape}\")\n",
    "#         print(f\"y_train shape: {y_train.shape}\")\n",
    "#         print(f\"X_test shape: {X_test.shape}\")\n",
    "#         print(f\"y_test shape: {y_test.shape}\")\n",
    "        \n",
    "#         # Log parameters\n",
    "#         mlflow.log_param(\"features\", features)\n",
    "#         mlflow.log_param(\"n_features\", len(features))\n",
    "#         mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "#         mlflow.log_param(\"objective\", \"reg:squarederror\")\n",
    "#         mlflow.log_param(\"n_train_samples\", len(X_train))\n",
    "        \n",
    "#         # Train model\n",
    "#         model = xgb.XGBRegressor(\n",
    "#             objective=\"reg:squarederror\",\n",
    "#             random_state=111,\n",
    "#             n_estimators=100,\n",
    "#             learning_rate=0.3,\n",
    "#             max_depth=6\n",
    "#         )\n",
    "        \n",
    "#         model.fit(X_train, y_train)\n",
    "        \n",
    "#         # Predictions in transformed space\n",
    "#         train_pred_transformed = model.predict(X_train)\n",
    "#         test_pred_transformed = model.predict(X_test)\n",
    "        \n",
    "#         # Inverse transform to get prices\n",
    "#         train_pred = inv_zscore_log_price(train_pred_transformed, train_mean, train_std)\n",
    "#         test_pred = inv_zscore_log_price(test_pred_transformed, train_mean, train_std)\n",
    "        \n",
    "#         train_actual = inv_zscore_log_price(y_train, train_mean, train_std)\n",
    "#         test_actual = inv_zscore_log_price(y_test, train_mean, train_std)\n",
    "        \n",
    "#         # Calculate metrics\n",
    "#         train_mape = median_absolute_percentage_error(train_actual, train_pred)\n",
    "#         test_mape = median_absolute_percentage_error(test_actual, test_pred)\n",
    "        \n",
    "#         # Additional metrics\n",
    "#         train_mae = np.median(np.abs(train_actual - train_pred))\n",
    "#         test_mae = np.median(np.abs(test_actual - test_pred))\n",
    "        \n",
    "#         # Log metrics\n",
    "#         mlflow.log_metric(\"train_mape\", train_mape)\n",
    "#         mlflow.log_metric(\"test_mape\", test_mape)\n",
    "#         mlflow.log_metric(\"overfitting_gap\", test_mape - train_mape)\n",
    "#         mlflow.log_metric(\"train_mae\", train_mae)\n",
    "#         mlflow.log_metric(\"test_mae\", test_mae)\n",
    "        \n",
    "#         # Log model\n",
    "#         mlflow.xgboost.log_model(model, \"model\")\n",
    "        \n",
    "#         # Store results\n",
    "#         results[exp_name] = {\n",
    "#             'train_mape': train_mape,\n",
    "#             'test_mape': test_mape,\n",
    "#             'train_mae': train_mae,\n",
    "#             'test_mae': test_mae,\n",
    "#             'overfitting_gap': test_mape - train_mape\n",
    "#         }\n",
    "        \n",
    "#         print(f\"\\nResults:\")\n",
    "#         print(f\"  Train MAPE: {train_mape:.2f}%\")\n",
    "#         print(f\"  Test MAPE: {test_mape:.2f}%\")\n",
    "#         print(f\"  Overfitting Gap: {test_mape - train_mape:.2f}%\")\n",
    "#         print(f\"  Train MAE: ${train_mae:.2f}\")\n",
    "#         print(f\"  Test MAE: ${test_mae:.2f}\")\n",
    "\n",
    "# # Print comparison table\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"EXPERIMENT COMPARISON\")\n",
    "# print(\"=\"*80)\n",
    "# print(f\"{'Experiment':<30} {'Train MAPE':>12} {'Test MAPE':>12} {'Improvement':>12}\")\n",
    "# print(\"-\"*80)\n",
    "\n",
    "# baseline_test_mape = results['baseline']['test_mape']\n",
    "\n",
    "# for exp_name, metrics in results.items():\n",
    "#     improvement = baseline_test_mape - metrics['test_mape']\n",
    "#     improvement_pct = (improvement / baseline_test_mape) * 100\n",
    "    \n",
    "#     print(f\"{exp_name:<30} {metrics['train_mape']:>11.2f}% {metrics['test_mape']:>11.2f}% {improvement_pct:>10.1f}%\")\n",
    "\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# # Conclusion\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"CONCLUSION: Census Data Impact\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# best_exp = min(results.items(), key=lambda x: x[1]['test_mape'])\n",
    "# print(f\"\\nBest performing model: {best_exp[0]}\")\n",
    "# print(f\"Test MAPE: {best_exp[1]['test_mape']:.2f}%\")\n",
    "\n",
    "# improvement = baseline_test_mape - best_exp[1]['test_mape']\n",
    "# improvement_pct = (improvement / baseline_test_mape) * 100\n",
    "\n",
    "# if improvement > 0:\n",
    "#     print(f\"\\nCensus data IMPROVED model performance by {improvement:.2f} percentage points ({improvement_pct:.1f}%)\")\n",
    "#     print(\"\\nRecommendation: INCLUDE census features in production model\")\n",
    "# else:\n",
    "#     print(f\"\\nCensus data DID NOT improve model performance\")\n",
    "#     print(\"\\nRecommendation: EXCLUDE census features - adds complexity without benefit\")\n",
    "\n",
    "# print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b724644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TESTING MODEL IMPROVEMENTS\n",
      "================================================================================\n",
      "\n",
      "Baseline (from previous experiments): 5.86% Test MAPE\n",
      "================================================================================\n",
      "\n",
      "[1/5] Testing: Adding 2022 data to training set...\n",
      "  Train MAPE: 3.71%\n",
      "  Test MAPE: 5.96%\n",
      "  vs Baseline: -0.10pp\n",
      "\n",
      "[2/5] Testing: Feature engineering (price per sqft, bed-to-bath ratio)...\n",
      "  Train MAPE: 3.54%\n",
      "  Test MAPE: 6.27%\n",
      "  vs Baseline: -0.41pp\n",
      "\n",
      "[3/5] Testing: Hyperparameter tuning (trying different configurations)...\n",
      "  Config 1: Test MAPE = 6.21%\n",
      "  Config 2: Test MAPE = 6.40%\n",
      "  Config 3: Test MAPE = 5.96%\n",
      "  Best Test MAPE: 5.96%\n",
      "  vs Baseline: -0.10pp\n",
      "\n",
      "[4/5] Testing: Removing outliers from training data...\n",
      "  Removed 849 outliers\n",
      "  Test MAPE: 5.44%\n",
      "  vs Baseline: +0.42pp\n",
      "\n",
      "[5/5] Testing: Different target transformation (log only)...\n",
      "  Test MAPE: 5.77%\n",
      "  vs Baseline: +0.09pp\n",
      "\n",
      "================================================================================\n",
      "IMPROVEMENT EXPERIMENTS SUMMARY\n",
      "================================================================================\n",
      "Baseline:                     5.86% MAPE\n",
      "1. With 2022 data:           5.96% MAPE  (-0.10pp)\n",
      "2. Feature engineering:      6.27% MAPE  (-0.41pp)\n",
      "3. Hyperparameter tuning:    5.96% MAPE  (-0.10pp)\n",
      "4. Remove outliers:          5.44% MAPE  (+0.42pp)\n",
      "5. Log-only transform:       5.77% MAPE  (+0.09pp)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import xgboost as xgb\n",
    "# import mlflow\n",
    "# import mlflow.xgboost\n",
    "\n",
    "# # Load data - make fresh copies to avoid mutation\n",
    "# census_df = pd.read_csv('census.csv', index_col=0)\n",
    "# train_df_original = pd.read_csv('train.csv', index_col=0)\n",
    "# test_df_original = pd.read_csv('test.csv', index_col=0)\n",
    "# df_2022 = pd.read_csv('data_2022.csv', index_col=0)\n",
    "\n",
    "# # Calculate train statistics from ORIGINAL data\n",
    "# train_mean = train_df_original['price'].apply(np.log).mean()\n",
    "# train_std = train_df_original['price'].apply(np.log).std()\n",
    "\n",
    "# def median_absolute_percentage_error(actual, predicted):\n",
    "#     return np.median((np.abs(actual - predicted) / actual)) * 100\n",
    "\n",
    "# def inv_zscore_log_price(y, mean, std):\n",
    "#     return np.exp((y * std) + mean)\n",
    "\n",
    "# mlflow.set_experiment(\"beekin_rent_prediction_improvements\")\n",
    "\n",
    "# print(\"=\"*80)\n",
    "# print(\"TESTING MODEL IMPROVEMENTS\")\n",
    "# print(\"=\"*80)\n",
    "# print(f\"\\nBaseline (from previous experiments): 5.86% Test MAPE\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# # ============================================================================\n",
    "# # IMPROVEMENT 1: Add 2022 data to training set (more recent data)\n",
    "# # ============================================================================\n",
    "# print(\"\\n[1/5] Testing: Adding 2022 data to training set...\")\n",
    "\n",
    "# with mlflow.start_run(run_name=\"baseline_with_2022_data\"):\n",
    "#     # Combine train and 2022 data\n",
    "#     combined_train = pd.concat([train_df_original, df_2022], ignore_index=True)\n",
    "    \n",
    "#     features = ['latitude', 'longitude', 'property_type', 'sqft', 'beds', 'baths', 'days_since_2014']\n",
    "    \n",
    "#     X_train = combined_train[features]\n",
    "#     y_train = combined_train['trans_log_price']\n",
    "    \n",
    "#     X_test = test_df_original[features]\n",
    "#     y_test = test_df_original['trans_log_price']\n",
    "    \n",
    "#     model = xgb.XGBRegressor(\n",
    "#         objective=\"reg:squarederror\",\n",
    "#         random_state=111,\n",
    "#         n_estimators=100,\n",
    "#         max_depth=6,\n",
    "#         learning_rate=0.3\n",
    "#     )\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     train_pred = inv_zscore_log_price(model.predict(X_train), train_mean, train_std)\n",
    "#     test_pred = inv_zscore_log_price(model.predict(X_test), train_mean, train_std)\n",
    "#     train_actual = inv_zscore_log_price(y_train, train_mean, train_std)\n",
    "#     test_actual = inv_zscore_log_price(y_test, train_mean, train_std)\n",
    "    \n",
    "#     train_mape = median_absolute_percentage_error(train_actual, train_pred)\n",
    "#     test_mape = median_absolute_percentage_error(test_actual, test_pred)\n",
    "    \n",
    "#     mlflow.log_param(\"training_data\", \"train + 2022\")\n",
    "#     mlflow.log_param(\"n_samples\", len(X_train))\n",
    "#     mlflow.log_metric(\"train_mape\", train_mape)\n",
    "#     mlflow.log_metric(\"test_mape\", test_mape)\n",
    "    \n",
    "#     print(f\"  Train MAPE: {train_mape:.2f}%\")\n",
    "#     print(f\"  Test MAPE: {test_mape:.2f}%\")\n",
    "#     improvement_1 = 5.86 - test_mape\n",
    "#     print(f\"  vs Baseline: {improvement_1:+.2f}pp\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # IMPROVEMENT 2: Feature engineering - interaction terms (FIXED)\n",
    "# # ============================================================================\n",
    "# print(\"\\n[2/5] Testing: Feature engineering (price per sqft, bed-to-bath ratio)...\")\n",
    "\n",
    "# with mlflow.start_run(run_name=\"engineered_features\"):\n",
    "#     # Fresh copies\n",
    "#     train_df = train_df_original.copy()\n",
    "#     test_df = test_df_original.copy()\n",
    "    \n",
    "#     # Create new features with safe division\n",
    "#     for df in [train_df, test_df]:\n",
    "#         # Replace 0 beds/baths with 0.5 to avoid division issues\n",
    "#         df['beds_safe'] = df['beds'].replace(0, 0.5)\n",
    "#         df['baths_safe'] = df['baths'].replace(0, 0.5)\n",
    "        \n",
    "#         df['sqft_per_bed'] = df['sqft'] / df['beds_safe']\n",
    "#         df['sqft_per_bath'] = df['sqft'] / df['baths_safe']\n",
    "#         df['bed_bath_ratio'] = df['beds_safe'] / df['baths_safe']\n",
    "#         df['total_rooms'] = df['beds'] + df['baths']\n",
    "        \n",
    "#         # Check for inf/nan and replace\n",
    "#         df['sqft_per_bed'] = df['sqft_per_bed'].replace([np.inf, -np.inf], np.nan).fillna(df['sqft'].median())\n",
    "#         df['sqft_per_bath'] = df['sqft_per_bath'].replace([np.inf, -np.inf], np.nan).fillna(df['sqft'].median())\n",
    "#         df['bed_bath_ratio'] = df['bed_bath_ratio'].replace([np.inf, -np.inf], np.nan).fillna(1.0)\n",
    "    \n",
    "#     features = ['latitude', 'longitude', 'property_type', 'sqft', 'beds', 'baths', \n",
    "#                 'days_since_2014', 'sqft_per_bed', 'sqft_per_bath', 'bed_bath_ratio', 'total_rooms']\n",
    "    \n",
    "#     X_train = train_df[features]\n",
    "#     y_train = train_df['trans_log_price']\n",
    "#     X_test = test_df[features]\n",
    "#     y_test = test_df['trans_log_price']\n",
    "    \n",
    "#     model = xgb.XGBRegressor(\n",
    "#         objective=\"reg:squarederror\",\n",
    "#         random_state=111,\n",
    "#         n_estimators=100,\n",
    "#         max_depth=6,\n",
    "#         learning_rate=0.3\n",
    "#     )\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     train_pred = inv_zscore_log_price(model.predict(X_train), train_mean, train_std)\n",
    "#     test_pred = inv_zscore_log_price(model.predict(X_test), train_mean, train_std)\n",
    "#     train_actual = inv_zscore_log_price(y_train, train_mean, train_std)\n",
    "#     test_actual = inv_zscore_log_price(y_test, train_mean, train_std)\n",
    "    \n",
    "#     train_mape = median_absolute_percentage_error(train_actual, train_pred)\n",
    "#     test_mape = median_absolute_percentage_error(test_actual, test_pred)\n",
    "    \n",
    "#     mlflow.log_param(\"features\", \"baseline + engineered\")\n",
    "#     mlflow.log_metric(\"train_mape\", train_mape)\n",
    "#     mlflow.log_metric(\"test_mape\", test_mape)\n",
    "    \n",
    "#     print(f\"  Train MAPE: {train_mape:.2f}%\")\n",
    "#     print(f\"  Test MAPE: {test_mape:.2f}%\")\n",
    "#     improvement_2 = 5.86 - test_mape\n",
    "#     print(f\"  vs Baseline: {improvement_2:+.2f}pp\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # IMPROVEMENT 3: Hyperparameter tuning\n",
    "# # ============================================================================\n",
    "# print(\"\\n[3/5] Testing: Hyperparameter tuning (trying different configurations)...\")\n",
    "\n",
    "# # Fresh data\n",
    "# features = ['latitude', 'longitude', 'property_type', 'sqft', 'beds', 'baths', 'days_since_2014']\n",
    "# X_train = train_df_original[features]\n",
    "# y_train = train_df_original['trans_log_price']\n",
    "# X_test = test_df_original[features]\n",
    "# y_test = test_df_original['trans_log_price']\n",
    "\n",
    "# param_sets = [\n",
    "#     {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8},\n",
    "#     {'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.9},\n",
    "#     {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.85},\n",
    "# ]\n",
    "\n",
    "# best_test_mape = float('inf')\n",
    "# best_params = None\n",
    "\n",
    "# for i, params in enumerate(param_sets):\n",
    "#     with mlflow.start_run(run_name=f\"tuned_params_{i+1}\"):\n",
    "#         model = xgb.XGBRegressor(\n",
    "#             objective=\"reg:squarederror\",\n",
    "#             random_state=111,\n",
    "#             **params\n",
    "#         )\n",
    "#         model.fit(X_train, y_train)\n",
    "        \n",
    "#         test_pred = inv_zscore_log_price(model.predict(X_test), train_mean, train_std)\n",
    "#         test_actual = inv_zscore_log_price(y_test, train_mean, train_std)\n",
    "#         test_mape = median_absolute_percentage_error(test_actual, test_pred)\n",
    "        \n",
    "#         mlflow.log_params(params)\n",
    "#         mlflow.log_metric(\"test_mape\", test_mape)\n",
    "        \n",
    "#         if test_mape < best_test_mape:\n",
    "#             best_test_mape = test_mape\n",
    "#             best_params = params\n",
    "        \n",
    "#         print(f\"  Config {i+1}: Test MAPE = {test_mape:.2f}%\")\n",
    "\n",
    "# improvement_3 = 5.86 - best_test_mape\n",
    "# print(f\"  Best Test MAPE: {best_test_mape:.2f}%\")\n",
    "# print(f\"  vs Baseline: {improvement_3:+.2f}pp\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # IMPROVEMENT 4: Remove outliers from training\n",
    "# # ============================================================================\n",
    "# print(\"\\n[4/5] Testing: Removing outliers from training data...\")\n",
    "\n",
    "# with mlflow.start_run(run_name=\"outliers_removed\"):\n",
    "#     # Remove extreme prices (beyond 3 standard deviations)\n",
    "#     price_mean = train_df_original['price'].mean()\n",
    "#     price_std = train_df_original['price'].std()\n",
    "    \n",
    "#     train_clean = train_df_original[\n",
    "#         (train_df_original['price'] > price_mean - 3*price_std) & \n",
    "#         (train_df_original['price'] < price_mean + 3*price_std)\n",
    "#     ].copy()\n",
    "    \n",
    "#     # Recalculate train stats on clean data\n",
    "#     train_mean_clean = train_clean['price'].apply(np.log).mean()\n",
    "#     train_std_clean = train_clean['price'].apply(np.log).std()\n",
    "    \n",
    "#     features = ['latitude', 'longitude', 'property_type', 'sqft', 'beds', 'baths', 'days_since_2014']\n",
    "#     X_train = train_clean[features]\n",
    "#     y_train = train_clean['trans_log_price']\n",
    "#     X_test = test_df_original[features]\n",
    "#     y_test = test_df_original['trans_log_price']\n",
    "    \n",
    "#     model = xgb.XGBRegressor(\n",
    "#         objective=\"reg:squarederror\",\n",
    "#         random_state=111,\n",
    "#         n_estimators=100,\n",
    "#         max_depth=6,\n",
    "#         learning_rate=0.3\n",
    "#     )\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     test_pred = inv_zscore_log_price(model.predict(X_test), train_mean_clean, train_std_clean)\n",
    "#     test_actual = inv_zscore_log_price(y_test, train_mean_clean, train_std_clean)\n",
    "#     test_mape = median_absolute_percentage_error(test_actual, test_pred)\n",
    "    \n",
    "#     mlflow.log_param(\"outliers_removed\", True)\n",
    "#     mlflow.log_param(\"n_samples_before\", len(train_df_original))\n",
    "#     mlflow.log_param(\"n_samples_after\", len(train_clean))\n",
    "#     mlflow.log_metric(\"test_mape\", test_mape)\n",
    "    \n",
    "#     print(f\"  Removed {len(train_df_original) - len(train_clean)} outliers\")\n",
    "#     print(f\"  Test MAPE: {test_mape:.2f}%\")\n",
    "#     improvement_4 = 5.86 - test_mape\n",
    "#     print(f\"  vs Baseline: {improvement_4:+.2f}pp\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # IMPROVEMENT 5: Different target transformation (log only, no z-score)\n",
    "# # ============================================================================\n",
    "# print(\"\\n[5/5] Testing: Different target transformation (log only)...\")\n",
    "\n",
    "# with mlflow.start_run(run_name=\"log_transform_only\"):\n",
    "#     features = ['latitude', 'longitude', 'property_type', 'sqft', 'beds', 'baths', 'days_since_2014']\n",
    "#     X_train = train_df_original[features]\n",
    "#     y_train_log = np.log(train_df_original['price'])  # Just log, no z-score\n",
    "    \n",
    "#     X_test = test_df_original[features]\n",
    "#     y_test_log = np.log(test_df_original['price'])\n",
    "    \n",
    "#     model = xgb.XGBRegressor(\n",
    "#         objective=\"reg:squarederror\",\n",
    "#         random_state=111,\n",
    "#         n_estimators=100,\n",
    "#         max_depth=6,\n",
    "#         learning_rate=0.3\n",
    "#     )\n",
    "#     model.fit(X_train, y_train_log)\n",
    "    \n",
    "#     test_pred = np.exp(model.predict(X_test))\n",
    "#     test_actual = test_df_original['price'].values\n",
    "#     test_mape = median_absolute_percentage_error(test_actual, test_pred)\n",
    "    \n",
    "#     mlflow.log_param(\"transform\", \"log_only\")\n",
    "#     mlflow.log_metric(\"test_mape\", test_mape)\n",
    "    \n",
    "#     print(f\"  Test MAPE: {test_mape:.2f}%\")\n",
    "#     improvement_5 = 5.86 - test_mape\n",
    "#     print(f\"  vs Baseline: {improvement_5:+.2f}pp\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"IMPROVEMENT EXPERIMENTS SUMMARY\")\n",
    "# print(\"=\"*80)\n",
    "# print(f\"Baseline:                     5.86% MAPE\")\n",
    "# print(f\"1. With 2022 data:           {5.86 - improvement_1:.2f}% MAPE  ({improvement_1:+.2f}pp)\")\n",
    "# print(f\"2. Feature engineering:      {5.86 - improvement_2:.2f}% MAPE  ({improvement_2:+.2f}pp)\")\n",
    "# print(f\"3. Hyperparameter tuning:    {best_test_mape:.2f}% MAPE  ({improvement_3:+.2f}pp)\")\n",
    "# print(f\"4. Remove outliers:          {5.86 - improvement_4:.2f}% MAPE  ({improvement_4:+.2f}pp)\")\n",
    "# print(f\"5. Log-only transform:       {5.86 - improvement_5:.2f}% MAPE  ({improvement_5:+.2f}pp)\")\n",
    "# print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
