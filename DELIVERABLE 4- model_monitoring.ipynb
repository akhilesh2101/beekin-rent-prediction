{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df92538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xgboost as xgb\n",
    "\n",
    "def monitor_model_performance(model_registry_path, test_data_path):\n",
    "    \"\"\"\n",
    "    Monitor performance difference between current and previous model.\n",
    "    \n",
    "    Acceptable ranges:\n",
    "    - CRITICAL: MAPE increase > 1.0 percentage point → ROLLBACK\n",
    "    - WARNING: MAPE increase > 15% relative → INVESTIGATE  \n",
    "    - PASS: All other cases\n",
    "    \n",
    "    Returns: status ('PASS', 'WARNING', 'FAIL')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define thresholds\n",
    "    ABSOLUTE_THRESHOLD = 1.0  # percentage points\n",
    "    RELATIVE_THRESHOLD = 15   # percent\n",
    "    \n",
    "    # Helper functions\n",
    "    def load_model(model_dir):\n",
    "        model = xgb.XGBRegressor()\n",
    "        model.load_model(str(model_dir / \"model.json\"))\n",
    "        return model\n",
    "    \n",
    "    def load_metadata(model_dir):\n",
    "        with open(model_dir / \"metadata.json\", 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    def calculate_mape(actual, predicted):\n",
    "        return np.median(np.abs(actual - predicted) / actual) * 100\n",
    "    \n",
    "    def inv_transform(y, mean, std):\n",
    "        return np.exp((y * std) + mean)\n",
    "    \n",
    "    # Get current and previous models\n",
    "    registry = Path(model_registry_path)\n",
    "    all_models = sorted([d for d in registry.iterdir() if d.is_dir() and d.name.startswith('model_')])\n",
    "    \n",
    "    if len(all_models) < 2:\n",
    "        print(\"Not enough models for comparison\")\n",
    "        return 'BASELINE'\n",
    "    \n",
    "    current_model_dir = all_models[-1]\n",
    "    previous_model_dir = all_models[-2]\n",
    "    \n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(f'{test_data_path}/test.csv', index_col=0)\n",
    "    \n",
    "    # Evaluate both models\n",
    "    results = {}\n",
    "    for name, model_dir in [('current', current_model_dir), ('previous', previous_model_dir)]:\n",
    "        model = load_model(model_dir)\n",
    "        metadata = load_metadata(model_dir)\n",
    "        \n",
    "        features = metadata['features']\n",
    "        X_test = test_df[features]\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        predicted_prices = inv_transform(y_pred, metadata['train_mean'], metadata['train_std'])\n",
    "        actual_prices = test_df['price'].values\n",
    "        \n",
    "        mape = calculate_mape(actual_prices, predicted_prices)\n",
    "        results[name] = {'mape': mape, 'model': model_dir.name}\n",
    "    \n",
    "    # Compare performance\n",
    "    mape_diff = results['current']['mape'] - results['previous']['mape']\n",
    "    mape_pct_change = (mape_diff / results['previous']['mape']) * 100\n",
    "    \n",
    "    # Determine status\n",
    "    if mape_diff > ABSOLUTE_THRESHOLD:\n",
    "        status = 'FAIL'\n",
    "        action = 'ROLLBACK'\n",
    "    elif mape_pct_change > RELATIVE_THRESHOLD:\n",
    "        status = 'WARNING'\n",
    "        action = 'INVESTIGATE'\n",
    "    else:\n",
    "        status = 'PASS'\n",
    "        action = 'DEPLOY'\n",
    "    \n",
    "    # Print report\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL PERFORMANCE MONITORING\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Current Model:  {results['current']['model']}\")\n",
    "    print(f\"  MAPE: {results['current']['mape']:.2f}%\")\n",
    "    print(f\"\\nPrevious Model: {results['previous']['model']}\")\n",
    "    print(f\"  MAPE: {results['previous']['mape']:.2f}%\")\n",
    "    print(f\"\\nChange: {mape_diff:+.2f} points ({mape_pct_change:+.1f}%)\")\n",
    "    print(f\"\\nStatus: {status}\")\n",
    "    print(f\"Action: {action}\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Save results\n",
    "    monitoring_log = {\n",
    "        'current_mape': results['current']['mape'],\n",
    "        'previous_mape': results['previous']['mape'],\n",
    "        'mape_diff': mape_diff,\n",
    "        'mape_pct_change': mape_pct_change,\n",
    "        'status': status,\n",
    "        'action': action\n",
    "    }\n",
    "    \n",
    "    with open(current_model_dir / \"monitoring_result.json\", 'w') as f:\n",
    "        json.dump(monitoring_log, f, indent=2)\n",
    "    \n",
    "    return status\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    status = monitor_model_performance(\n",
    "        model_registry_path=\"./model_registry\",\n",
    "        test_data_path=\"./data\"\n",
    "    )\n",
    "    \n",
    "    if status == 'FAIL':\n",
    "        raise ValueError(\"Model performance degraded - rollback recommended\")\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
